{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f57d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65eafd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=100\n",
    "\n",
    "training_data=datasets.FashionMNIST(root=\"../fashion_mnist\",train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_data=datasets.FashionMNIST(root=\"../fashion_mnist\",train=False,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "train_dataloader=DataLoader(training_data,batch_size=batchsize)\n",
    "test_dataloader=DataLoader(test_data,batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters lwk\n",
    "sequence_len=28\n",
    "input_len=28\n",
    "hidden_size=128\n",
    "num_layer=2\n",
    "num_classes=10\n",
    "num_epochs=10\n",
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7af2050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "   def __init__(self,input_len,hidden_size,num_classes,num_layer):\n",
    "      super(LSTM,self).__init__()\n",
    "      self.hidden_size=hidden_size\n",
    "      self.num_layer=num_layer\n",
    "      self.lstm=nn.LSTM(input_len,hidden_size,num_layer,batch_first=True)\n",
    "      self.output_layer=nn.Linear(hidden_size,num_classes)\n",
    "\n",
    "   def forward(self,X):\n",
    "      hidden_states=torch.zeros(self.num_layer,X.size(0),self.hidden_size)\n",
    "      cell_states=torch.zeros(self.num_layer,X.size(0),self.hidden_size)\n",
    "\n",
    "      out,_ = self.lstm(X,(hidden_states,cell_states))\n",
    "      out=self.output_layer(out[:,-1,:])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77a45633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=LSTM(input_len,hidden_size,num_classes,num_layer)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0ccabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aed91b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "\n",
    "def train(num_epochs,model,train_dataloader,loss_func,optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch,(images,labels) in enumerate(train_dataloader):\n",
    "            images=images.reshape(-1,sequence_len,input_len)\n",
    "            outputs=model(images)\n",
    "            loss=loss_func(outputs,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if(batch+1)%100==0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}],Step [{batch+1}/{len(train_dataloader)}],Loss:{loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "972a5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20],Step [100/600],Loss:0.9209\n",
      "Epoch [1/20],Step [200/600],Loss:0.7461\n",
      "Epoch [1/20],Step [300/600],Loss:0.4398\n",
      "Epoch [1/20],Step [400/600],Loss:0.4459\n",
      "Epoch [1/20],Step [500/600],Loss:0.6706\n",
      "Epoch [1/20],Step [600/600],Loss:0.3560\n",
      "Epoch [2/20],Step [100/600],Loss:0.4388\n",
      "Epoch [2/20],Step [200/600],Loss:0.3015\n",
      "Epoch [2/20],Step [300/600],Loss:0.3675\n",
      "Epoch [2/20],Step [400/600],Loss:0.4645\n",
      "Epoch [2/20],Step [500/600],Loss:0.4749\n",
      "Epoch [2/20],Step [600/600],Loss:0.2355\n",
      "Epoch [3/20],Step [100/600],Loss:0.2927\n",
      "Epoch [3/20],Step [200/600],Loss:0.3062\n",
      "Epoch [3/20],Step [300/600],Loss:0.2655\n",
      "Epoch [3/20],Step [400/600],Loss:0.3392\n",
      "Epoch [3/20],Step [500/600],Loss:0.4389\n",
      "Epoch [3/20],Step [600/600],Loss:0.2216\n",
      "Epoch [4/20],Step [100/600],Loss:0.3039\n",
      "Epoch [4/20],Step [200/600],Loss:0.2744\n",
      "Epoch [4/20],Step [300/600],Loss:0.2544\n",
      "Epoch [4/20],Step [400/600],Loss:0.2783\n",
      "Epoch [4/20],Step [500/600],Loss:0.3929\n",
      "Epoch [4/20],Step [600/600],Loss:0.1937\n",
      "Epoch [5/20],Step [100/600],Loss:0.2747\n",
      "Epoch [5/20],Step [200/600],Loss:0.2746\n",
      "Epoch [5/20],Step [300/600],Loss:0.2136\n",
      "Epoch [5/20],Step [400/600],Loss:0.3046\n",
      "Epoch [5/20],Step [500/600],Loss:0.3746\n",
      "Epoch [5/20],Step [600/600],Loss:0.1668\n",
      "Epoch [6/20],Step [100/600],Loss:0.3479\n",
      "Epoch [6/20],Step [200/600],Loss:0.3144\n",
      "Epoch [6/20],Step [300/600],Loss:0.1732\n",
      "Epoch [6/20],Step [400/600],Loss:0.2891\n",
      "Epoch [6/20],Step [500/600],Loss:0.3669\n",
      "Epoch [6/20],Step [600/600],Loss:0.1758\n",
      "Epoch [7/20],Step [100/600],Loss:0.2765\n",
      "Epoch [7/20],Step [200/600],Loss:0.2801\n",
      "Epoch [7/20],Step [300/600],Loss:0.2092\n",
      "Epoch [7/20],Step [400/600],Loss:0.2693\n",
      "Epoch [7/20],Step [500/600],Loss:0.3569\n",
      "Epoch [7/20],Step [600/600],Loss:0.2146\n",
      "Epoch [8/20],Step [100/600],Loss:0.2292\n",
      "Epoch [8/20],Step [200/600],Loss:0.2986\n",
      "Epoch [8/20],Step [300/600],Loss:0.2022\n",
      "Epoch [8/20],Step [400/600],Loss:0.2523\n",
      "Epoch [8/20],Step [500/600],Loss:0.3153\n",
      "Epoch [8/20],Step [600/600],Loss:0.2194\n",
      "Epoch [9/20],Step [100/600],Loss:0.2423\n",
      "Epoch [9/20],Step [200/600],Loss:0.2692\n",
      "Epoch [9/20],Step [300/600],Loss:0.2233\n",
      "Epoch [9/20],Step [400/600],Loss:0.2681\n",
      "Epoch [9/20],Step [500/600],Loss:0.2826\n",
      "Epoch [9/20],Step [600/600],Loss:0.1966\n",
      "Epoch [10/20],Step [100/600],Loss:0.1471\n",
      "Epoch [10/20],Step [200/600],Loss:0.2400\n",
      "Epoch [10/20],Step [300/600],Loss:0.1940\n",
      "Epoch [10/20],Step [400/600],Loss:0.2449\n",
      "Epoch [10/20],Step [500/600],Loss:0.2938\n",
      "Epoch [10/20],Step [600/600],Loss:0.1724\n",
      "Epoch [11/20],Step [100/600],Loss:0.2239\n",
      "Epoch [11/20],Step [200/600],Loss:0.2724\n",
      "Epoch [11/20],Step [300/600],Loss:0.1556\n",
      "Epoch [11/20],Step [400/600],Loss:0.2103\n",
      "Epoch [11/20],Step [500/600],Loss:0.2743\n",
      "Epoch [11/20],Step [600/600],Loss:0.2106\n",
      "Epoch [12/20],Step [100/600],Loss:0.2500\n",
      "Epoch [12/20],Step [200/600],Loss:0.2624\n",
      "Epoch [12/20],Step [300/600],Loss:0.1750\n",
      "Epoch [12/20],Step [400/600],Loss:0.2273\n",
      "Epoch [12/20],Step [500/600],Loss:0.2877\n",
      "Epoch [12/20],Step [600/600],Loss:0.1705\n",
      "Epoch [13/20],Step [100/600],Loss:0.1736\n",
      "Epoch [13/20],Step [200/600],Loss:0.2072\n",
      "Epoch [13/20],Step [300/600],Loss:0.1638\n",
      "Epoch [13/20],Step [400/600],Loss:0.2497\n",
      "Epoch [13/20],Step [500/600],Loss:0.2773\n",
      "Epoch [13/20],Step [600/600],Loss:0.1688\n",
      "Epoch [14/20],Step [100/600],Loss:0.4387\n",
      "Epoch [14/20],Step [200/600],Loss:0.2923\n",
      "Epoch [14/20],Step [300/600],Loss:0.2633\n",
      "Epoch [14/20],Step [400/600],Loss:0.5221\n",
      "Epoch [14/20],Step [500/600],Loss:0.4461\n",
      "Epoch [14/20],Step [600/600],Loss:0.3353\n",
      "Epoch [15/20],Step [100/600],Loss:0.2189\n",
      "Epoch [15/20],Step [200/600],Loss:0.2852\n",
      "Epoch [15/20],Step [300/600],Loss:0.3407\n",
      "Epoch [15/20],Step [400/600],Loss:0.2546\n",
      "Epoch [15/20],Step [500/600],Loss:0.3532\n",
      "Epoch [15/20],Step [600/600],Loss:0.2261\n",
      "Epoch [16/20],Step [100/600],Loss:0.2937\n",
      "Epoch [16/20],Step [200/600],Loss:0.2974\n",
      "Epoch [16/20],Step [300/600],Loss:0.3432\n",
      "Epoch [16/20],Step [400/600],Loss:0.3471\n",
      "Epoch [16/20],Step [500/600],Loss:0.6471\n",
      "Epoch [16/20],Step [600/600],Loss:0.8948\n",
      "Epoch [17/20],Step [100/600],Loss:1.2091\n",
      "Epoch [17/20],Step [200/600],Loss:0.9963\n",
      "Epoch [17/20],Step [300/600],Loss:0.6808\n",
      "Epoch [17/20],Step [400/600],Loss:0.7426\n",
      "Epoch [17/20],Step [500/600],Loss:0.7304\n",
      "Epoch [17/20],Step [600/600],Loss:0.5383\n",
      "Epoch [18/20],Step [100/600],Loss:0.6090\n",
      "Epoch [18/20],Step [200/600],Loss:0.6851\n",
      "Epoch [18/20],Step [300/600],Loss:0.4507\n",
      "Epoch [18/20],Step [400/600],Loss:0.6683\n",
      "Epoch [18/20],Step [500/600],Loss:0.6188\n",
      "Epoch [18/20],Step [600/600],Loss:0.3705\n",
      "Epoch [19/20],Step [100/600],Loss:0.5463\n",
      "Epoch [19/20],Step [200/600],Loss:0.7798\n",
      "Epoch [19/20],Step [300/600],Loss:0.6998\n",
      "Epoch [19/20],Step [400/600],Loss:0.6559\n",
      "Epoch [19/20],Step [500/600],Loss:0.6586\n",
      "Epoch [19/20],Step [600/600],Loss:0.4809\n",
      "Epoch [20/20],Step [100/600],Loss:0.5741\n",
      "Epoch [20/20],Step [200/600],Loss:0.5813\n",
      "Epoch [20/20],Step [300/600],Loss:0.5018\n",
      "Epoch [20/20],Step [400/600],Loss:0.6097\n",
      "Epoch [20/20],Step [500/600],Loss:0.7345\n",
      "Epoch [20/20],Step [600/600],Loss:0.7082\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs,model,train_dataloader,loss_func,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14e7105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images:76.77777777777777%\n"
     ]
    }
   ],
   "source": [
    "#testing loop\n",
    "with torch.no_grad():\n",
    "    correct=0\n",
    "    total=0\n",
    "    acc=0\n",
    "    best_acc=0\n",
    "    for images,labels in test_dataloader:\n",
    "        images=images.reshape(-1,sequence_len,input_len)\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "        acc=100*correct/total\n",
    "        if acc>best_acc:\n",
    "            best_acc=acc\n",
    "            torch.save(model.state_dict(), 'best_lstm.pth')\n",
    "    print(f\"Accuracy of the model on the test images:{best_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e62cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
