{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f57d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65eafd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:30<00:00, 873kB/s] \n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 158kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:02<00:00, 2.20MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 17.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "batchsize=100\n",
    "\n",
    "training_data=datasets.FashionMNIST(root=\"../fashion_mnist\",train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_data=datasets.FashionMNIST(root=\"../fashion_mnist\",train=False,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "train_dataloader=DataLoader(training_data,batch_size=batchsize)\n",
    "test_dataloader=DataLoader(test_data,batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efe18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters lwk\n",
    "sequence_len=28\n",
    "input_len=28\n",
    "hidden_size=128\n",
    "num_layer=2\n",
    "num_classes=10\n",
    "num_epochs=10\n",
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af2050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "   def __init__(self,input_len,hidden_size,num_classes,num_layer):\n",
    "      super(LSTM,self).__init__()\n",
    "      self.hidden_size=hidden_size\n",
    "      self.num_layer=num_layer\n",
    "      self.lstm=nn.LSTM(input_len,hidden_size,num_layer,batch_first=True)\n",
    "      self.output_layer=nn.Linear(hidden_size,num_classes)\n",
    "\n",
    "   def forward(self,X):\n",
    "      hidden_states=torch.zeros(self.num_layer,X.size(0),self.hidden_size)\n",
    "      cell_states=torch.zeros(self.num_layer,X.size(0),self.hidden_size)\n",
    "\n",
    "      out,_ = self.lstm(X,(hidden_states,cell_states))\n",
    "      out=self.output_layer(out[:,-1,:])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a45633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=LSTM(input_len,hidden_size,num_classes,num_layer)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ccabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed91b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "\n",
    "def train(num_epochs,model,train_dataloader,loss_func,optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch,(images,labels) in enumerate(train_dataloader):\n",
    "            images=images.reshape(-1,sequence_len,input_len)\n",
    "            outputs=model(images)\n",
    "            loss=loss_func(outputs,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if(batch+1)%100==0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}],Step [{batch+1}/{len(train_dataloader)}],Loss:{loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972a5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10],Step [100/600],Loss:0.9308\n",
      "Epoch [1/10],Step [200/600],Loss:0.8574\n",
      "Epoch [1/10],Step [300/600],Loss:0.5480\n",
      "Epoch [1/10],Step [400/600],Loss:0.4933\n",
      "Epoch [1/10],Step [500/600],Loss:0.6332\n",
      "Epoch [1/10],Step [600/600],Loss:0.4495\n",
      "Epoch [2/10],Step [100/600],Loss:0.4347\n",
      "Epoch [2/10],Step [200/600],Loss:0.3629\n",
      "Epoch [2/10],Step [300/600],Loss:0.3426\n",
      "Epoch [2/10],Step [400/600],Loss:0.4892\n",
      "Epoch [2/10],Step [500/600],Loss:0.5684\n",
      "Epoch [2/10],Step [600/600],Loss:0.2672\n",
      "Epoch [3/10],Step [100/600],Loss:0.3030\n",
      "Epoch [3/10],Step [200/600],Loss:0.2879\n",
      "Epoch [3/10],Step [300/600],Loss:0.2370\n",
      "Epoch [3/10],Step [400/600],Loss:0.4291\n",
      "Epoch [3/10],Step [500/600],Loss:0.4832\n",
      "Epoch [3/10],Step [600/600],Loss:0.2791\n",
      "Epoch [4/10],Step [100/600],Loss:0.2697\n",
      "Epoch [4/10],Step [200/600],Loss:0.2798\n",
      "Epoch [4/10],Step [300/600],Loss:0.2582\n",
      "Epoch [4/10],Step [400/600],Loss:0.3099\n",
      "Epoch [4/10],Step [500/600],Loss:0.4735\n",
      "Epoch [4/10],Step [600/600],Loss:0.2538\n",
      "Epoch [5/10],Step [100/600],Loss:0.2579\n",
      "Epoch [5/10],Step [200/600],Loss:0.3057\n",
      "Epoch [5/10],Step [300/600],Loss:0.2104\n",
      "Epoch [5/10],Step [400/600],Loss:0.3504\n",
      "Epoch [5/10],Step [500/600],Loss:0.4196\n",
      "Epoch [5/10],Step [600/600],Loss:0.2100\n",
      "Epoch [6/10],Step [100/600],Loss:0.2434\n",
      "Epoch [6/10],Step [200/600],Loss:0.2894\n",
      "Epoch [6/10],Step [300/600],Loss:0.2171\n",
      "Epoch [6/10],Step [400/600],Loss:0.3649\n",
      "Epoch [6/10],Step [500/600],Loss:0.3838\n",
      "Epoch [6/10],Step [600/600],Loss:0.2527\n",
      "Epoch [7/10],Step [100/600],Loss:0.2271\n",
      "Epoch [7/10],Step [200/600],Loss:0.2553\n",
      "Epoch [7/10],Step [300/600],Loss:0.2104\n",
      "Epoch [7/10],Step [400/600],Loss:0.2809\n",
      "Epoch [7/10],Step [500/600],Loss:0.3554\n",
      "Epoch [7/10],Step [600/600],Loss:0.2342\n",
      "Epoch [8/10],Step [100/600],Loss:0.1988\n",
      "Epoch [8/10],Step [200/600],Loss:0.2586\n",
      "Epoch [8/10],Step [300/600],Loss:0.1847\n",
      "Epoch [8/10],Step [400/600],Loss:0.2990\n",
      "Epoch [8/10],Step [500/600],Loss:0.3379\n",
      "Epoch [8/10],Step [600/600],Loss:0.2177\n",
      "Epoch [9/10],Step [100/600],Loss:0.1817\n",
      "Epoch [9/10],Step [200/600],Loss:0.2621\n",
      "Epoch [9/10],Step [300/600],Loss:0.1914\n",
      "Epoch [9/10],Step [400/600],Loss:0.2763\n",
      "Epoch [9/10],Step [500/600],Loss:0.2831\n",
      "Epoch [9/10],Step [600/600],Loss:0.2188\n",
      "Epoch [10/10],Step [100/600],Loss:0.1925\n",
      "Epoch [10/10],Step [200/600],Loss:0.2446\n",
      "Epoch [10/10],Step [300/600],Loss:0.2266\n",
      "Epoch [10/10],Step [400/600],Loss:0.3660\n",
      "Epoch [10/10],Step [500/600],Loss:0.2830\n",
      "Epoch [10/10],Step [600/600],Loss:0.1875\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs,model,train_dataloader,loss_func,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e7105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images:92.0%\n"
     ]
    }
   ],
   "source": [
    "#testing loop\n",
    "with torch.no_grad():\n",
    "    correct=0\n",
    "    total=0\n",
    "    acc=0\n",
    "    best_acc=0\n",
    "    for images,labels in test_dataloader:\n",
    "        images=images.reshape(-1,sequence_len,input_len)\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "        acc=100*correct/total\n",
    "        if acc>best_acc:\n",
    "            best_acc=acc\n",
    "            torch.save(model.state_dict(), 'best_lstm.pth')\n",
    "    print(f\"Accuracy of the model on the test images:{best_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e62cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
